{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPython Notebook Sample\n",
    "### Jukka Ruponen, IBM, 2016-03-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis: \"In order to get best tips, taxi drivers should favor carrying 3-4 people at once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the hypothesis, this notebook will do the following:\n",
    "1. Read NYC taxidata from Open API\n",
    "1. Normalize and test the data\n",
    "1. Perform analysis\n",
    "1. Provide few **optional** steps just to show you how you may export data as a CSV file and then upload it elsewhere\n",
    "1. Visualize the result to confirm (or reject) our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NYC taxidata from REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_taxidata = requests.get('https://data.cityofnewyork.us/resource/2yzn-sicd.json')\n",
    "json_taxidata = raw_taxidata.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print out the data - DO NOT RUN THIS STEP unless you really want to see lots of data printed out in here!!!\n",
    "json_taxidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the lenght of data (number of lines)?\n",
    "print len(json_taxidata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets normalize and test the data, and try to find an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets import json_normalize since we can use it to convert JSON data to tabular data\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a normalized data frame and print out the first five rows\n",
    "taxidata = json_normalize(json_taxidata)\n",
    "taxidata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the numeric values are actually text strings, we'll first need to convert them to float\n",
    "taxidata2 = taxidata.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test: What is the biggest amount of fare paid?\n",
    "taxidata2['fare_amount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test: What is the biggest amount of tip paid?\n",
    "taxidata2['tip_amount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test: How many individual taxi trips with different number of passengers?\n",
    "taxidata2['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just to play around, setting index to vendorid\n",
    "passengers = taxidata2.set_index(taxidata[\"vendor_id\"])\n",
    "# Drop off unneeded columns to clean the data\n",
    "passengers.drop(['extra','mta_tax','vendor_id','dropoff_latitude','dropoff_longitude','pickup_latitude','pickup_longitude','rate_code','store_and_fwd_flag'], axis=1, inplace=True)\n",
    "passengers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test: How much tips were given total by the number of passangers in the taxi?\n",
    "passengers.groupby('passenger_count')['tip_amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Got it! So group the data by passenger_count and extract average stats for each 'number of passengers' group\n",
    "averages = passengers.groupby(['passenger_count']).agg({'fare_amount': 'mean',\n",
    "                                             'tip_amount': 'mean',\n",
    "                                             'trip_distance': 'mean'})\n",
    "averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Storing the previous output as a CSV file on the local GPFS file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the last result as CSV file on the local GPFS filesystem (just to make it clear: It's NOT saved in the \"Object Store\")\n",
    "_.to_csv('NYC_taxi_passenger_tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just to confirm its there, list files in the current directory of GPFS\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just to confirm it's content, print out the first 4 lines of the saved file\n",
    "!head -n4 'NYC_taxi_passenger_tips.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Uploading the stored CSV file from local GPFS onto an external Hadoop (if you have one) for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this step if you do not have available Hadoop system that can accessed from this cloud environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change these variables according to your target HDFS\n",
    "HDFS_WebhdfsUrl = \"https://bi-hadoop-prod-2470.services.dal.bluemix.net:8443/gateway/default/webhdfs/v1\" # Replace with your WebhdfsUrl\n",
    "HDFS_userid = \"\" # Replace with your WebHDFS userid\n",
    "HDFS_password = \"\" # Replace with your WebHDFS password\n",
    "Local_filename = \"NYC_taxi_passenger_tips.csv\" # This is the local filename you just stored above with the _.to_csv('filename') command\n",
    "HDFS_filepath = \"/user/biblumix/test/test.csv\" # This is the full path and filename to be uploaded on the target HDFS (the directory will be created, if not exist)\n",
    "HDFS_operator = \"op=CREATE\" # 'op=CREATE' is an operator to create a new file. For other operators, see: https://hadoop.apache.org/docs/r1.0.4/webhdfs.html\n",
    "HDFS_maxTime = 45 # This is time in seconds after which the transfer will timeout, success or not. Make sure its long enough to cover full transfer time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When you run this cell, the variables you've set above will be used to execute the upload\n",
    "!curl -i -L -k -s --user \"$HDFS_userid\":\"$HDFS_password\" --max-time $HDFS_maxTime -X PUT -T \"$Local_filename\" \"$HDFS_WebhdfsUrl$HDFS_filepath?$HDFS_operator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Uploading the stored CSV file from local GPFS onto your Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful if you want to, for example, download the stored CSV file on your own computer.\n",
    "The cells on below will perform uploading the file on your Object Storage in Bluemix, from where you can then manually download it.\n",
    "Skip this step if you don't want to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in the missing values on below according to your Object Store credentials.\n",
    "# IMPORTANT: Make sure the FILENAME corresponds to the one you stored on the GPFS!\n",
    "\n",
    "# Hint: If you are not sure what to enter here, place your cursor in the empty cell above and then\n",
    "# click \"Insert to code\" option under one of the existing files on your \"Data Source\" panel on the right.\n",
    "# This will give you the values you should use on below, except the filename which is now different.\n",
    "\n",
    "credentials = {\n",
    "    'auth_url': 'https://identity.open.softlayer.com',\n",
    "    'region': 'dallas',\n",
    "    'domain_id': '',\n",
    "    'username': '',\n",
    "    'password': '',\n",
    "    'filename': 'NYC_taxi_passenger_tips.csv',\n",
    "    'container': 'notebooks'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't change anything here. When this function is called it will use the credentials above to perform the following:\n",
    "# 1) acquire from the Object Storage the required authentication token and storage URL, and then\n",
    "# 2) use curl command in a shell to upload the file to the Object Store\n",
    "def osUploadFile(credentials):\n",
    "    '''This function will use the given credentials to upload the file'''\n",
    "\n",
    "    auth_url = ''.join([credentials['auth_url'], '/v3/auth/tokens'])\n",
    "    request = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n",
    "            'password': credentials['password']}}}}}\n",
    "    auth_headers = {'Content-Type': 'application/json'}\n",
    "    auth_response = requests.post(url=auth_url, data=json.dumps(request), headers=auth_headers)\n",
    "    resp1_body = auth_response.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                if(e2['interface']=='public'and e2['region']==credentials['region']):\n",
    "                    upload_url = ''.join([e2['url'],'/', credentials['container'], '/', credentials['filename']])                    \n",
    "    auth_token = auth_response.headers['x-subject-token']\n",
    "    upload_headers = ''.join([\"X-Auth-Token: \",auth_token])\n",
    "    filename = credentials['filename']\n",
    "    !curl -i -L -k -s -H \"$upload_headers\" $upload_url -X PUT -T $filename\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osUploadFile(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets visualize the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#passengers = averages.ix['passenger_count']\n",
    "averages.plot(kind='bar', figsize=(8,5), title=\"Average earnings by # of passengers\" % passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra challenge: What other valuable information could you derive from the data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}